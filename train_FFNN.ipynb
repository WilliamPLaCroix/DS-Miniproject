{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install torchmetrics"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dZYPoHjQowPr",
    "outputId": "7a2e67c7-b168-4fd5-af69-5c0cdd6bc3e6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchmetrics.classification import BinaryF1Score\n",
    "from torchmetrics.classification import BinaryPrecision\n",
    "from torchmetrics.classification import BinaryRecall\n",
    "from torchmetrics.classification import BinaryAccuracy\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "id": "-yXW4XLhl2dg"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# reload splits from csv files\n",
    "X_train = pd.read_csv('relabelled_data/X_train.csv')\n",
    "X_dev = pd.read_csv('relabelled_data/X_dev.csv')\n",
    "X_test = pd.read_csv('relabelled_data/X_test.csv')\n",
    "y_train = pd.read_csv('relabelled_data/y_train.csv')\n",
    "y_dev = pd.read_csv('relabelled_data/y_dev.csv')\n",
    "y_test = pd.read_csv('relabelled_data/y_test.csv')\n",
    "\n",
    "# verify data integrity\n",
    "print(X_train.shape)\n",
    "print(X_dev.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_dev.shape)\n",
    "print(y_test.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i1B8Qsgil6RD",
    "outputId": "7f9bfa1a-e61c-4ac9-86c9-bcc718ce4a23"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# make dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super(MyDataset, self).__init__()\n",
    "        assert x.shape[0] == y.shape[0] # assuming shape[0] = dataset size\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ],
   "metadata": {
    "id": "Tf4CpcPWm_A9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_X = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "train_y = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "dev_X = torch.tensor(X_dev.values, dtype=torch.float32)\n",
    "dev_y = torch.tensor(y_dev.values, dtype=torch.float32)\n",
    "test_X = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "test_y = torch.tensor(y_test.values, dtype=torch.float32)"
   ],
   "metadata": {
    "id": "EURg5sg_nB4s"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "traindata = MyDataset(train_X, train_y)\n",
    "trainloader = torch.utils.data.DataLoader(traindata, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "id": "VafyGXzCnvAN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "devdata = MyDataset(dev_X, dev_y)\n",
    "devloader = torch.utils.data.DataLoader(devdata, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "id": "6xswiq6_n6B0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "testdata = MyDataset(test_X, test_y)\n",
    "testloader = torch.utils.data.DataLoader(testdata, batch_size=64, shuffle=True)"
   ],
   "metadata": {
    "id": "AWAbewYan8Sz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# checkpoint functions\n",
    "def checkpoint(model, filename):\n",
    "    torch.save(model.state_dict(), filename)\n",
    "\n",
    "def resume(model, filename):\n",
    "    model.load_state_dict(torch.load(filename))\n",
    "\n",
    "def load_model(ModelClass ,filename):\n",
    "  model = ModelClass()\n",
    "  model.load_state_dict(torch.load(filename))\n",
    "  return model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# define the Network\n",
    "class MyNetwork(nn.Module):\n",
    "    def __init__(self, lr=0.0001):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.learning_rate = lr\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "        nn.Linear(10, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 500),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(500, 100),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(100, 1),\n",
    "        nn.Sigmoid()\n",
    ")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ],
   "metadata": {
    "id": "y2tszaQWoEje"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = MyNetwork(lr=0.01)"
   ],
   "metadata": {
    "id": "IcqiPJvCoPMW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epochs = 1000\n",
    "early_stop_thresh = 5\n",
    "best_accuracy = -1\n",
    "best_epoch = -1\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=model.learning_rate)\n",
    "\n",
    "Acc = BinaryAccuracy()\n",
    "Precision = BinaryPrecision()\n",
    "Recall = BinaryRecall()\n",
    "BF1 = BinaryF1Score()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "  for i,(x_train,y_train) in tqdm(enumerate(trainloader)):\n",
    "    model.train()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pred = model(x_train)\n",
    "    loss = loss_fn(pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# compute train metrics for current epoch\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    outputs_train = []\n",
    "    targets_train = []\n",
    "    for j ,(x_train, y_train) in enumerate(trainloader):\n",
    "        pred = model(x_train)\n",
    "        outputs_train.append(pred.round())\n",
    "        targets_train.append(y_train)\n",
    "\n",
    "    outputs_train = torch.cat(outputs_train)\n",
    "    targets_train = torch.cat(targets_train)\n",
    "\n",
    "    train_acc = Acc(outputs_train, targets_train)\n",
    "    train_p = Precision(outputs_train, targets_train)\n",
    "    train_r = Recall(outputs_train, targets_train)\n",
    "    train_f1 = BF1(outputs_train, targets_train)\n",
    "\n",
    "    print(f'Training accuracy for epoch {epoch} is: {train_acc}')\n",
    "    print(f'Training Precision for epoch {epoch} is: {train_p}')\n",
    "    print(f'Training Recall for epoch {epoch} is: {train_r}')\n",
    "    print(f'Training F1 for epoch {epoch} is: {train_f1} \\n')\n",
    "\n",
    "# compute dev metrics for current epoch\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    outputs_val = []\n",
    "    targets_val = []\n",
    "    for j ,(x_dev, y_dev) in enumerate(devloader):\n",
    "        pred = model(x_dev)\n",
    "        outputs_val.append(pred.round())\n",
    "        targets_val.append(y_dev)\n",
    "\n",
    "    outputs_val = torch.cat(outputs_val)\n",
    "    targets_val = torch.cat(targets_val)\n",
    "\n",
    "    val_acc = Acc(outputs_val, targets_val)\n",
    "    val_p = Precision(outputs_val, targets_val)\n",
    "    val_r = Recall(outputs_val, targets_val)\n",
    "    val_f1 = BF1(outputs_val, targets_val)\n",
    "\n",
    "    print(f'Validation accuracy for epoch {epoch} is: {val_acc}')\n",
    "    print(f'Validation Precision for epoch {epoch} is: {val_p}')\n",
    "    print(f'Validation Recall for epoch {epoch} is: {val_r}')\n",
    "    print(f'Validation F1 for epoch {epoch} is: {val_f1} \\n')\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        best_accuracy = val_acc\n",
    "        best_epoch = epoch\n",
    "        checkpoint(model, \"drive/MyDrive/DS-Project/models/ProfifPropheNet-v1.pt\")\n",
    "    elif epoch - best_epoch > early_stop_thresh:\n",
    "        print(\"Early stopped training at epoch %d\" % epoch)\n",
    "        break  # terminate the training loop\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U0okjq_0oUkE",
    "outputId": "1fbc4a3a-fba1-44ef-9ecc-00de3207228c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    for j ,(x_test, y_test) in enumerate(testloader):\n",
    "        pred = model(x_test)\n",
    "        outputs.append(pred.round())\n",
    "        targets.append(y_test)\n",
    "\n",
    "    outputs = torch.cat(outputs)\n",
    "    targets = torch.cat(targets)\n",
    "    print(f'test accuracy for best model is: {Acc(outputs, targets)}')\n",
    "    print(f'test Precision for best model is: {Precision(outputs, targets)}')\n",
    "    print(f'test Recall for best model is: {Recall(outputs, targets)}')\n",
    "    print(f'test F1 for best model is: {BF1(outputs, targets)} \\n')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "wL9yrIVm5t0W",
    "outputId": "04194beb-4ffd-44dd-89eb-8e317257df96"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# reload model\n",
    "model = MyNetwork()\n",
    "model.load_state_dict(torch.load(\"models/ProfifPropheNet-v1.pt\"))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJrHwMwlHW9f",
    "outputId": "65702f60-66be-4a8a-8815-98ce0cb64733"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Acc = BinaryAccuracy()\n",
    "Precision = BinaryPrecision()\n",
    "Recall = BinaryRecall()\n",
    "BF1 = BinaryF1Score()"
   ],
   "metadata": {
    "id": "03tpHIiYq97N"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = []\n",
    "    targets = []\n",
    "    for j ,(x_test, y_test) in enumerate(testloader):\n",
    "        pred = model(x_test)\n",
    "        outputs.append(pred.round())\n",
    "        targets.append(y_test)\n",
    "\n",
    "    outputs = torch.cat(outputs)\n",
    "    targets = torch.cat(targets)\n",
    "    print(f'test accuracy for best model is: {Acc(outputs, targets)}')\n",
    "    print(f'test Precision for best model is: {Precision(outputs, targets)}')\n",
    "    print(f'test Recall for best model is: {Recall(outputs, targets)}')\n",
    "    print(f'test F1 for best model is: {BF1(outputs, targets)} \\n')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cGvS1cPl858G",
    "outputId": "a4d4170d-5e8e-4065-fa5a-8e31c11459cf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(targets, outputs).ravel()\n",
    "\n",
    "print(\"True Negatives:\", tn)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "print(\"True Positives:\", tp)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QSqf7h3GX8Y2",
    "outputId": "77ba04d6-6548-4adc-8455-154ff644e393"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# dev confusion matrix\n",
    "dev_predictions = pd.DataFrame(columns=['y_pred', 'y_true'])\n",
    "with torch.no_grad():\n",
    "    for X, y in devloader:\n",
    "        X = X.to(torch.float32)\n",
    "        y = y.squeeze()\n",
    "        y_pred = model(X).squeeze(1).round()\n",
    "        y_frame = pd.DataFrame({'y_pred': y_pred, 'y_true': y})\n",
    "        dev_predictions = dev_predictions.append(y_frame, ignore_index=True)\n",
    "\n",
    "confusion = pd.crosstab(dev_predictions['y_true'], dev_predictions['y_pred'], rownames=['True'],\n",
    "                        colnames=['Predicted'], margins=True)\n",
    "print(confusion)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecT0adpAaXCB",
    "outputId": "efc6c7b4-611a-4403-f281-3d328aaa441c"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# train confusion matrix\n",
    "train_predictions = pd.DataFrame(columns=['y_pred', 'y_true'])\n",
    "with torch.no_grad():\n",
    "    for X, y in trainloader:\n",
    "        X = X.to(torch.float32)\n",
    "        y = y.squeeze()\n",
    "        y_pred = model(X).squeeze(1).round()\n",
    "        y_frame = pd.DataFrame({'y_pred': y_pred, 'y_true': y})\n",
    "        train_predictions = train_predictions.append(y_frame, ignore_index=True)\n",
    "\n",
    "confusion = pd.crosstab(dev_predictions['y_true'], dev_predictions['y_pred'], rownames=['True'],\n",
    "                        colnames=['Predicted'], margins=True)\n",
    "print(confusion)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HE7QKRJQc-An",
    "outputId": "31df0a76-36b9-4b62-d40c-511c8bc85ef0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test confusion matrix\n",
    "test_predictions = pd.DataFrame(columns=['y_pred', 'y_true'])\n",
    "with torch.no_grad():\n",
    "    for X, y in testloader:\n",
    "        X = X.to(torch.float32)\n",
    "        y = y.squeeze()\n",
    "        y_pred = model(X).squeeze(1).round()\n",
    "        y_frame = pd.DataFrame({'y_pred': y_pred, 'y_true': y})\n",
    "        test_predictions = test_predictions.append(y_frame, ignore_index=True)\n",
    "\n",
    "confusion = pd.crosstab(dev_predictions['y_true'], dev_predictions['y_pred'], rownames=['True'],\n",
    "                        colnames=['Predicted'], margins=True)\n",
    "print(confusion)"
   ],
   "metadata": {
    "id": "ckSPLZp9dGgX",
    "outputId": "2c87ded2-7e65-4dbd-9261-b8513486cbb0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
